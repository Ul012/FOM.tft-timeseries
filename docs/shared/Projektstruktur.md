# Projektstruktur ‚Äì FOM.tft-timeseries

**Datum:** 2025-11-15  
**Script:** ‚Äì  
**Ziel & Inhalt:** Gibt eine vollst√§ndige √úbersicht √ºber die Struktur des gesamten Projekts. Erkl√§rt die Rollen der Ordner `data`, `modeling`, `utils`, `visualization` sowie geplante Evaluation. Beschreibt Datenfluss, Zust√§ndigkeiten und Erweiterbarkeit der Pipeline.


---

## üóÇÔ∏è 1. `src/` ‚Äì Hauptverzeichnis

```text
src/
‚îú‚îÄ‚îÄ data/
‚îú‚îÄ‚îÄ modeling/
‚îú‚îÄ‚îÄ utils/
‚îú‚îÄ‚îÄ visualization/
‚îî‚îÄ‚îÄ config.py
```

---

## üìä 2. `data/` ‚Äì Datenaufbereitung (Preprocessing)

Beinhaltet alle Schritte bis zur Erstellung eines modellfertigen Datensatzes.

| Datei | Aufgabe |
|-------|---------|
| `data_alignment.py` | Harmonisierung und optionale Normalisierung der Zeitachsen. |
| `data_cleaning.py` | Bereinigung, Imputation, Konsistenzpr√ºfungen. |
| `feature_engineering.py` | Erstellung von Kalender- und Feiertags-Features. |
| `cyclical_encoder.py` | Zyklische Kodierung periodischer Variablen (sin/cos). |
| `lag_features.py` | Erzeugt Lag- und Rolling-Features per `groupby().shift()`. |
| `view_data.py` | Kurze visuelle Kontrolle der Roh- und Zwischendaten. |

**Ausgabe dieser Stufe:**  
- `data/processed/train_features_cyc_lag.parquet` (Features inkl. Zyklen und Lags)  
‚Üí dient als Input f√ºr `model_dataset.py`.

---

## ü§ñ 3. `modeling/` ‚Äì Modellierung und Training

Enth√§lt alle Skripte zur Vorbereitung, Spezifikation und zum Training der Modelle.

| Datei | Aufgabe |
|-------|---------|
| `model_dataset.py` | Split in Train/Validation/Test, schreibt `train/val/test.parquet` und `meta.json`. |
| `dataset_tft.py` | Leitet Feature-Listen (known/unknown/static) ab, erstellt `dataset_spec.json`. |
| `trainer_tft.py` | Trainiert den Temporal Fusion Transformer, speichert Logs, Checkpoints und JSON-Reports. |
| *(geplant)* `trainer_arima.py` | ARIMA-Modelltraining auf aggregierten oder einzelnen Zeitreihen. |
| *(geplant)* `trainer_prophet.py` | Prophet-Training mit automatischer Saisonalit√§tserkennung. |

**Wichtige Datenfl√ºsse:**

1. `model_dataset.py`:
   - Eingabe: `data/processed/train_features_cyc_lag.parquet`
   - Ausgabe:  
     - `data/processed/train.parquet`  
     - `data/processed/val.parquet`  
     - `data/processed/test.parquet`  
     - `data/processed/meta.json`

2. `dataset_tft.py`:
   - Eingabe: `train/val/test.parquet` aus `data/processed/`
   - Ausgabe: `data/processed/dataset_spec.json` (TFT-Datensatzspezifikation)

3. `trainer_tft.py`:
   - Eingabe: `dataset_spec.json` + YAML aus `configs/`
   - Ausgabe:
     - Logs: `logs/tft/run_YYYYMMDD_HHMMSS/metrics.csv`, `hparams.yaml`, ‚Ä¶
     - Checkpoints: `results/tft/checkpoints/run_YYYYMMDD_HHMMSS/*.ckpt`
     - Evaluations-JSONs: `results/evaluation/run_YYYYMMDD_HHMMSS/{results,summary}.json`

---

## üß∞ 4. `utils/` ‚Äì Hilfsfunktionen & Werkzeuge

Dient zur Wiederverwendung und modularen Wartung.

| Datei | Aufgabe |
|-------|---------|
| `config_loader.py` | L√§dt und validiert YAML-Konfigurationen f√ºr den Trainer. |
| `json_results.py` | Aggregiert Metriken aus `metrics.csv` und exportiert JSON-Ergebnisse pro Run. |
| `load_trained_tft.py` | Utility zum Laden eines gespeicherten TFT-Checkpoints (optional). |
| `__init__.py` | Kennzeichnung als Paket; ggf. globale Utility-Imports. |

> Utils-Skripte werden meist importiert und nicht direkt als Pipeline-Schritt ausgef√ºhrt.

---

## üìà 5. `visualization/` ‚Äì Plots und Diagnosen (Evaluationsebene)

Fasst alle Visualisierungen zusammen, die nach oder w√§hrend des Trainings ben√∂tigt werden.

| Datei | Aufgabe |
|-------|---------|
| `data_alignment_plot.py` | Visualisierung der Datenharmonisierung. |
| `data_cleaning_plot.py` | Darstellung bereinigter Werte, Vergleich Vorher/Nachher. |
| `plot_learning_rate.py` | Verl√§ufe der Loss-Kurven und ggf. der Learning-Rate. |
| `view_data_plot.py` | Allgemeine Explorations-Plots f√ºr das Datenverst√§ndnis. |
| *(geplant)* `evaluation_plot.py` | Darstellung der finalen Modellvergleiche (TFT vs. ARIMA vs. Prophet). |

Plots werden typischerweise unter `results/plots/` abgelegt.

---

## üìä 6. Evaluierung (geplant)

Geplant ist ein eigener Ordner `src/evaluation/`, der folgende Skripte enthalten wird:

| Datei | Aufgabe |
|-------|---------|
| `evaluate_tft.py` | Evaluation der TFT-Runs auf Basis von `metrics.csv` und `summary.json` (Metriken, Fehlerma√üe, JSON/CSV-Reports). |
| `evaluate_comparison.py` | Cross-Modell-Vergleich (TFT vs. ARIMA vs. Prophet) auf Basis der konsolidierten Resultate. |

Typische Ausgaben:

- `results/evaluation/runs_summary.csv`
- ggf. weitere CSV/JSON-Dateien f√ºr die Seminararbeit.

---

## ‚öôÔ∏è 7. `config.py` ‚Äì Zentrale Steuerung

- Globale Konstanten: `DATETIME_COLUMN`, `GROUP_COLS`, `TARGET_COL`  
- Pfade: `RAW_DIR`, `INTERIM_DIR`, `PROCESSED_DIR`, `MODEL_INPUT_PATH`  
- Feature-Konfigurationen: `LAG_CONF`, `TFT_DATASET` (Sequenzl√§ngen, Prefixes, Flags)  
- Split-Parameter: `VAL_START`, `TEST_START`, `SPLIT_RATIOS`

**Wichtig:** Trainings- und Modell-Hyperparameter (Learning Rate, Batch Size, Epochen, Modellgr√∂√üen, Devices etc.) stehen **nicht** in `config.py`, sondern in den YAML-Dateien im Ordner `configs/`.

---

## ‚úÖ 8. Einordnung und Erweiterbarkeit

- **Pipeline-relevant:**  
  `src/data/` ‚Üí `src/modeling/` (Datenaufbereitung bis Training)

- **Unterst√ºtzend, optional:**  
  `src/utils/`, `src/visualization/`, sp√§ter `src/evaluation/`  

- **Erweiterbar:**  
  Zus√§tzliche Trainer-Module (z.‚ÄØB. `trainer_arima.py`, `trainer_prophet.py`) k√∂nnen nach demselben Muster aufgebaut werden wie `trainer_tft.py`:
  - trainieren Modelle,
  - loggen Metriken in `logs/<modell>/run_*`,
  - schreiben Ergebnisse nach `results/<modell>/...`.

Damit bleibt das Projekt trotz Erweiterungen (mehr Modelle, mehr Szenarien) **√ºbersichtlich, modular und gut dokumentierbar**.
